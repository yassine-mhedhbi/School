{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import csv\n",
    "import string\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import scipy.sparse as sps\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {ord(char): None for char in string.punctuation}\n",
    "R = open(\"Datasets/yelp-train.txt\",\"r\").read().translate(table).lower()\n",
    "Text = R.split(\" \")\n",
    "yelp_top = Counter(Text).most_common(10000)\n",
    "dic_y = dict(yelp_top)\n",
    "A = {}\n",
    "i = 0\n",
    "for k in dic_y:\n",
    "    A[k] = i\n",
    "    i+= 1\n",
    "\n",
    "yelp_v = open(\"yelp-vocab.txt\",\"a\")\n",
    "for i in range(10000):\n",
    "\tline = str(i+1) + \"\\t\" + yelp_top[i][0] + \"\\t\" + str(yelp_top[i][1]) + \"\\n\"\n",
    "\tyelp_v.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_train_x = []\n",
    "yelp_train_y = []\n",
    "f = open(\"Datasets/yelp-train.txt\",\"r\").read().translate(table).lower()\n",
    "x = f.split(\"\\n\")\n",
    "for i in range(len(x)-1):\n",
    "    a = x[i].split(\"\\t\")\n",
    "    yelp_train_x = yelp_train_x + [a[0]]\n",
    "    yelp_train_y = yelp_train_y + [int(a[1])]\n",
    "                        \n",
    "yelp_valid_x = []\n",
    "yelp_valid_y = []\n",
    "f = open(\"Datasets/yelp-valid.txt\",\"r\").read().translate(table).lower()\n",
    "x = f.split(\"\\n\")\n",
    "for i in range(len(x)-1):\n",
    "    a = x[i].split(\"\\t\")\n",
    "    yelp_valid_x = yelp_valid_x + [a[0]]\n",
    "    yelp_valid_y = yelp_valid_y + [int(a[1])]\n",
    "                        \n",
    "yelp_test_x = []\n",
    "yelp_test_y = []\n",
    "f = open(\"Datasets/yelp-test.txt\",\"r\").read().translate(table).lower()\n",
    "x = f.split(\"\\n\")\n",
    "for i in range(len(x)-1):\n",
    "    a = x[i].split(\"\\t\")\n",
    "    yelp_test_x = yelp_test_x + [a[0]]\n",
    "    yelp_test_y = yelp_test_y + [int(a[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagofwords(data, dic,w):\n",
    "    DM_binary = []\n",
    "    DM_frequency = []\n",
    "    for x in data:\n",
    "        vector_binary = np.zeros(len(dic))\n",
    "        vector_frequency = np.zeros(len(dic))\n",
    "        for y in x:\n",
    "            if y in dic:\n",
    "                index = w[y]\n",
    "                if (vector_binary[index] == 0):\n",
    "                    vector_binary[index] = 1\n",
    "                vector_frequency[index] += 1                \n",
    "        DM_binary.append(vector_binary)\n",
    "        DM_frequency.append(vector_frequency)   \n",
    "    return DM_frequency, DM_binary\n",
    "\n",
    "train_y_f, train_y_b = bagofwords(yelp_train_x, dic_y,A)\n",
    "valid_y_f, valid_y_b = bagofwords(yelp_valid_x, dic_y,A)\n",
    "test_y_f, test_y_b = bagofwords(yelp_test_x, dic_y,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(train_y_b,yelp_train_y,valid_y_b,yelp_valid_y,test_y_b,yelp_test_y):\n",
    "    uniform= DummyClassifier(strategy='uniform')\n",
    "    uniform.fit(train_y_b, yelp_train_y)\n",
    "    print(\"The f1_measure on test set for Random classifier is :\" + str(f1_score(yelp_test_y,uniform.predict(test_y_b), average = 'micro')))\n",
    "\n",
    "\n",
    "    majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "    majority_classifier.fit(train_y_b, yelp_train_y)\n",
    "\n",
    "    print(\"The f1_measure on test set for majority-class classifier is :\" + str(f1_score(yelp_test_y, majority_classifier.predict(test_y_b), average = 'micro')))\n",
    "    \n",
    "    \n",
    "    classifier = BernoulliNB()\n",
    "    classifier.fit(train_y_b, yelp_train_y)\n",
    "    parameters = []\n",
    "    for i in range(0,100):\n",
    "        parameters.append(math.pow(10,(i-90)))\n",
    "    best = -1\n",
    "    k = 0\n",
    "    for i in parameters:\n",
    "        classifier.alpha = i\n",
    "        f1_measure = f1_score(yelp_valid_y,classifier.predict(valid_y_b), average='micro')\n",
    "        if (best < f1_measure):\n",
    "            k = i\n",
    "            best = f1_measure\n",
    "    classifier.alpha = k   \n",
    "\n",
    "    pn_test = classifier.predict(test_y_b)\n",
    "\n",
    "    test= f1_score(yelp_test_y,pn_test, average='micro')\n",
    "    print()\n",
    "    print(\"Test Result - naive classifier:\")\n",
    "    print(\"The F-measure is \" + str(test) + \"with best alpha is:\" +str(classifier.alpha) ) \n",
    "    \n",
    "    max_features = [i for i in range(1,20)]\n",
    "    min_samples_leaf = [i for i in range(1,20)]\n",
    "    max_depth = [i for i in range(1,20)]\n",
    "    tre = tree.DecisionTreeClassifier()\n",
    "    tre.fit(train_y_b, yelp_train_y)\n",
    "    best_f1_2 = -10\n",
    "    best_i = 0\n",
    "    best_j = 0\n",
    "    best_k = 0 \n",
    "    for i in max_features:\n",
    "        for j in min_samples_leaf:\n",
    "            for k in max_depth:\n",
    "                tree.max_features = i\n",
    "                tree.min_samples_leaf = j\n",
    "                tree.max_depth = k\n",
    "                f1_measure = f1_score(yelp_valid_y,tre.predict(valid_y_b), average='micro')\n",
    "                if (best_f1_2 < f1_measure):\n",
    "                    best_i = i\n",
    "                    best_j = j\n",
    "                    best_k = k \n",
    "                    best_f1_2 = f1_measure\n",
    "                \n",
    "\n",
    "    tre.max_features = best_i\n",
    "    tre.max_features = best_j\n",
    "    tre.max_features = best_k \n",
    "\n",
    "\n",
    "    pt_test = tre.predict(test_y_b)\n",
    "    test = f1_score(yelp_test_y,pt_test, average='micro')\n",
    "    print()\n",
    "    print(\"Test Result - tree classifier:\")\n",
    "    print(\"The F-measure is \" + str(test)) \n",
    "    \n",
    "    linear= LinearSVC()\n",
    "    linear.fit(train_y_b, yelp_train_y)\n",
    "    #svc_valid = lin_clf.predict(valid_y_b)\n",
    "    parameters = []\n",
    "    for i in range(0,100):\n",
    "        parameters.append(math.pow(10,(i-90)))\n",
    "    best = -1\n",
    "    k=0\n",
    "    for i in parameters:\n",
    "        linear.C = i\n",
    "        f1_measure = f1_score(yelp_valid_y,classifier.predict(valid_y_b), average='micro')\n",
    "        if (best < f1_measure):\n",
    "            k = i\n",
    "            best = f1_measure\n",
    "    linear.C = k   \n",
    "    svm_test = linear.predict(test_y_b)\n",
    "    test = f1_score(yelp_test_y,svm_test, average='micro')\n",
    "    print(\"Test Result - svm classifier:\")\n",
    "    print(\"The F-measure is \" + str(test) + \" with C:\" + str(linear.C) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on test set for Random classifier is :0.2045\n",
      "The f1_measure on test set for majority-class classifier is :0.351\n",
      "\n",
      "Test Result - naive classifier:\n",
      "The F-measure is 0.361with best alpha is:1e-90\n",
      "\n",
      "Test Result - tree classifier:\n",
      "The F-measure is 0.3015\n",
      "Test Result - svm classifier:\n",
      "The F-measure is 0.3675 with C:1e-90\n"
     ]
    }
   ],
   "source": [
    "# for binary rep:\n",
    "performance(train_y_b,yelp_train_y,valid_y_b,yelp_valid_y,test_y_b,yelp_test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on test set for Random classifier is :0.2005\n",
      "The f1_measure on test set for majority-class classifier is :0.351\n",
      "\n",
      "Test Result - naive classifier:\n",
      "The F-measure is 0.361with best alpha is:1e-90\n",
      "\n",
      "Test Result - tree classifier:\n",
      "The F-measure is 0.2865\n",
      "Test Result - svm classifier:\n",
      "The F-measure is 0.3525 with C:1e-90\n"
     ]
    }
   ],
   "source": [
    "performance(train_y_f,yelp_train_y,valid_y_f,yelp_valid_y,test_y_f,yelp_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
