{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "from numpy.linalg import inv\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import Counter\n",
    "import string\n",
    "import operator\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import scipy.sparse as sps\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train_x = []\n",
    "yelp_train_y = []\n",
    "yelp_valid_x = []\n",
    "yelp_valid_y = []\n",
    "yelp_test_x = []\n",
    "yelp_test_y = []\n",
    "\n",
    "translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "\n",
    "with open('./yelp-train.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_train_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_train_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./yelp-valid.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_valid_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_valid_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./yelp-test.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_test_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_test_y.append(int(line[-2]))\n",
    "        \n",
    "wordfreq = {}\n",
    "\n",
    "for row in yelp_train_x:\n",
    "    words = row.split(\" \")\n",
    "    j = 0\n",
    "    for word in words:\n",
    "        if word == ' ' or word == '':\n",
    "            continue\n",
    "        if word not in wordfreq:\n",
    "            wordfreq[word] = (j,1)\n",
    "            j += 1\n",
    "        else:\n",
    "            wordfreq[word] = (j, wordfreq[word][1]+ 1)\n",
    "    \n",
    "    \n",
    "\n",
    "sorted_wordfreq = sorted(wordfreq.items(), key=lambda x:x[1], reverse = True)[:10000]  \n",
    "sorted_wordfreq_dict = dict(sorted_wordfreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bag_of_words_represntation(data, sorted_wordfreq_dict):\n",
    "    DM_binary = []\n",
    "    DM_frequency = []\n",
    "    for x in data:\n",
    "        vector_binary = np.zeros(len(sorted_wordfreq_dict))\n",
    "        vector_frequency = np.zeros(len(sorted_wordfreq_dict))\n",
    "        for y in x.split(' '):\n",
    "            if y in sorted_wordfreq_dict:\n",
    "                index = sorted_wordfreq_dict[y][0]\n",
    "                if (vector_binary[index] == 0):\n",
    "                    vector_binary[index] = 1\n",
    "                vector_frequency[index] += 1                \n",
    "        DM_binary.append(vector_binary)\n",
    "        if (sum(vector_frequency) != 0):\n",
    "            vector_frequency = vector_frequency/sum(vector_frequency)\n",
    "        \n",
    "        DM_frequency.append(vector_frequency)   \n",
    "    return DM_frequency, DM_binary\n",
    "\n",
    "train_frequency_design, train_binary_design = bag_of_words_represntation(yelp_train_x, sorted_wordfreq_dict)\n",
    "valid_frequency_design, valid_binary_design = bag_of_words_represntation(yelp_valid_x, sorted_wordfreq_dict)\n",
    "test_frequency_design, test_binary_design = bag_of_words_represntation(yelp_test_x, sorted_wordfreq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_vocab = []\n",
    "for i in range(0,len(sorted_wordfreq)):\n",
    "    yelp_vocab.append([i, sorted_wordfreq[i][0], sorted_wordfreq[i][1]])\n",
    "yelp_train = []\n",
    "for i in range(0,len(yelp_train_x)):\n",
    "    toadd = []\n",
    "    for j in yelp_train_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(sorted_wordfreq_dict[j][0])\n",
    "    toadd.append(yelp_train_y[i])\n",
    "    yelp_train.append(toadd)        \n",
    "yelp_valid = []\n",
    "for i in range(0,len(yelp_valid_x)):\n",
    "    toadd = []\n",
    "    for j in yelp_valid_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(sorted_wordfreq_dict[j][0])\n",
    "    toadd.append(yelp_valid_y[i])\n",
    "    yelp_valid.append(toadd)\n",
    "yelp_test = []\n",
    "for i in range(0,len(yelp_test_x)):\n",
    "    toadd = []\n",
    "    for j in yelp_test_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(sorted_wordfreq_dict[j][0])\n",
    "    toadd.append(yelp_test_y[i])\n",
    "    yelp_test.append(toadd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on test set for bernoulli naive bayes using binary bag of words is :0.37\n",
      "Corresponding alpha is 1e-90\n",
      "The f1_measure on test set for classification tree using binary bag of words is :0.2975\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 1, 1, 1\n",
      "The f1_measure on test set for LinearSVC using binary bag of words is :0.36250000000000004\n",
      "The corresponding vlaue of C is1e-90\n",
      "The f1_measure on test set for Random classifier is :0.2025\n",
      "The f1_measure on test set for majority-class classifier is :0.351\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(yelp_valid_y,clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "\n",
    "print(\"The f1_measure on test set for bernoulli naive bayes using binary bag of words is :\" + str(f1_score(y_true = yelp_test_y, y_pred = clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0 \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(yelp_valid_y,decision_tree.predict(valid_binary_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.min_samples_leaf = best_j\n",
    "decision_tree.max_depth = best_k\n",
    "print(\"The f1_measure on test set for classification tree using binary bag of words is :\" + str(f1_score(y_true = yelp_test_y, y_pred = decision_tree.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" + str(best_i) +\n",
    "      \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "      \n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(yelp_valid_y,lin_clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for LinearSVC using binary bag of words is :\" + str(f1_score(yelp_test_y, lin_clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_binary_design, yelp_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" + str(f1_score(yelp_test_y,uniform_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is :\" + str(f1_score(yelp_test_y, majority_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on test set for bernoulli naive bayes using frequency bag of words is :0.37\n",
      "Corresponding alpha is 1e-90\n",
      "The f1_measure on test set for classification tree using frequency bag of words is :0.275\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 1, 1, 1\n",
      "The f1_measure on test set for LinearSVC using frequency bag of words is :0.37\n",
      "The corresponding vlaue of C is1e-90\n",
      "The f1_measure on test set for Random classifier is :0.20000000000000004\n",
      "The f1_measure on test set for majority-class classifier is :0.351\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(yelp_valid_y,clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for bernoulli naive bayes using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_test_y, y_pred = clf.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0 \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(yelp_valid_y,decision_tree.predict(valid_frequency_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.max_features = best_j\n",
    "decision_tree.max_features = best_k \n",
    "print(\"The f1_measure on test set for classification tree using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_test_y, y_pred = decision_tree.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" \n",
    "      + str(best_i) + \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(yelp_valid_y,lin_clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for LinearSVC using frequency bag of words is :\"\n",
    "      + str(f1_score(yelp_test_y, lin_clf.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_binary_design, yelp_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" \n",
    "      + str(f1_score(yelp_test_y,uniform_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is : \" + \n",
    "      str(f1_score(yelp_test_y, majority_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_train_x = []\n",
    "IMDB_train_y = []\n",
    "IMDB_valid_x = []\n",
    "IMDB_valid_y = []\n",
    "IMDB_test_x = []\n",
    "IMDB_test_y = []\n",
    "\n",
    "translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "\n",
    "with open('./IMDB-train.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_train_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_train_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./IMDB-valid.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_valid_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_valid_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./IMDB-test.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_test_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_test_y.append(int(line[-2]))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wordfreq = {}\n",
    "for row in IMDB_train_x:\n",
    "    words = row.split(\" \")\n",
    "    j = 0\n",
    "    for word in words:\n",
    "        if word == ' ' or word == '':\n",
    "            continue\n",
    "        if word not in wordfreq:\n",
    "            wordfreq[word] = (j,1)\n",
    "            j += 1\n",
    "        else:\n",
    "            wordfreq[word] = (j, wordfreq[word][1]+ 1)\n",
    "    \n",
    "sorted_wordfreq = sorted(wordfreq.items(), key=lambda x:x[1], reverse = True)[:10000]  \n",
    "sorted_wordfreq_dict = dict(sorted_wordfreq)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bag_of_words_represntation(data, sorted_wordfreq_dict):\n",
    "    DM_binary = []\n",
    "    DM_frequency = []\n",
    "    for x in data:\n",
    "        vector_binary = np.zeros(len(sorted_wordfreq_dict))\n",
    "        vector_frequency = np.zeros(len(sorted_wordfreq_dict))\n",
    "        for y in x.split(' '):\n",
    "            if y in sorted_wordfreq_dict:\n",
    "                index = sorted_wordfreq_dict[y][0]\n",
    "                if (vector_binary[index] == 0):\n",
    "                    vector_binary[index] = 1\n",
    "                vector_frequency[index] += 1                \n",
    "        DM_binary.append(vector_binary)\n",
    "        if (sum(vector_frequency) != 0):\n",
    "            vector_frequency = vector_frequency/sum(vector_frequency)\n",
    "        \n",
    "        DM_frequency.append(vector_frequency)   \n",
    "    return csr_matrix(DM_frequency), csr_matrix(DM_binary)\n",
    "\n",
    "train_frequency_design, train_binary_design = bag_of_words_represntation(IMDB_train_x, sorted_wordfreq_dict)\n",
    "valid_frequency_design, valid_binary_design = bag_of_words_represntation(IMDB_valid_x, sorted_wordfreq_dict)\n",
    "test_frequency_design, test_binary_design = bag_of_words_represntation(IMDB_test_x, sorted_wordfreq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_vocab = []\n",
    "for i in range(0,len(sorted_wordfreq)):\n",
    "    IMDB_vocab.append([i, sorted_wordfreq[i][0], sorted_wordfreq[i][1]])\n",
    "IMDB_train = []\n",
    "for i in range(0,len(IMDB_train_x)):\n",
    "    toadd = []\n",
    "    for j in IMDB_train_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(sorted_wordfreq_dict[j][0])\n",
    "    toadd.append(IMDB_train_y[i])\n",
    "    IMDB_train.append(toadd)        \n",
    "IMDB_valid = []\n",
    "for i in range(0,len(IMDB_valid_x)):\n",
    "    toadd = []\n",
    "    for j in IMDB_valid_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(sorted_wordfreq_dict[j][0])\n",
    "    toadd.append(IMDB_valid_y[i])\n",
    "    IMDB_valid.append(toadd)\n",
    "IMDB_test = []\n",
    "for i in range(0,len(IMDB_test_x)):\n",
    "    toadd = []\n",
    "    for j in IMDB_test_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(sorted_wordfreq_dict[j][0])\n",
    "    toadd.append(IMDB_test_y[i])\n",
    "    IMDB_test.append(toadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on test set for bernoulli naive bayes using binary bag of words is :0.52208\n",
      "Corresponding alpha is 1e-90\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "The f1_measure on test set for classification tree using binary bag of words is :0.51912\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 0, 0, 0\n",
      "The f1_measure on test set for LinearSVC using binary bag of words is :0.5226\n",
      "The corresponding vlaue of C is 1e-90\n",
      "The f1_measure on test set for Random classifier is :0.50624\n",
      "The f1_measure on test set for majority-class classifier is :0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "\n",
    "print(\"The f1_measure on test set for bernoulli naive bayes using binary bag of words is :\" \n",
    "      + str(f1_score(y_true =IMDB_test_y, y_pred = clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0 \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(IMDB_valid_y,decision_tree.predict(valid_binary_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = 0\n",
    "                best_j = 0\n",
    "                best_k = 0 \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.max_features = best_j\n",
    "decision_tree.max_features = best_k \n",
    "print(\"The f1_measure on test set for classification tree using binary bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_test_y, y_pred = decision_tree.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" \n",
    "      + str(best_i) + \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,lin_clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for LinearSVC using binary bag of words is :\" \n",
    "      + str(f1_score(IMDB_test_y, lin_clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_binary_design, IMDB_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" \n",
    "      + str(f1_score(IMDB_test_y,uniform_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "uniform_classifier.predict(test_binary_design)\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is :\" \n",
    "      + str(f1_score(IMDB_test_y, majority_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on test set for bernoulli naive bayes using binary bag of words is :0.52208\n",
      "Corresponding alpha is 1e-90\n",
      "The f1_measure on test set for classification tree using binary bag of words is :0.5198\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 0, 0, 0\n",
      "The f1_measure on test set for LinearSVC using binary bag of words is :0.50492\n",
      "The corresponding vlaue of C is 1e-90\n",
      "The f1_measure on test set for Random classifier is :0.50224\n",
      "The f1_measure on test set for majority-class classifier is :0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_frequency_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "\n",
    "print(\"The f1_measure on test set for bernoulli naive bayes using frequency bag of words is :\" + \n",
    "      str(f1_score(y_true =IMDB_test_y, y_pred = clf.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_frequency_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "q = [] \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(IMDB_valid_y,decision_tree.predict(valid_frequency_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = 0\n",
    "                best_j = 0\n",
    "                best_k = 0 \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.max_features = best_j\n",
    "decision_tree.max_features = best_k \n",
    "print(\"The f1_measure on test set for classification tree using frequency bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_test_y, y_pred = decision_tree.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" \n",
    "      + str(best_i) + \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,lin_clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for LinearSVC using frequency bag of words is :\" + \n",
    "      str(f1_score(IMDB_test_y, lin_clf.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_frequency_design, IMDB_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" + \n",
    "      str(f1_score(IMDB_test_y,uniform_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_frequency_design, IMDB_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is :\" + \n",
    "      str(f1_score(IMDB_test_y, majority_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
