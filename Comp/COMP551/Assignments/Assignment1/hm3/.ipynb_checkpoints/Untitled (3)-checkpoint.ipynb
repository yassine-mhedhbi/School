{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "from numpy.linalg import inv\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import Counter\n",
    "import string\n",
    "import operator\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import scipy.sparse as sps\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './yelp-train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-71ea0fea4df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./yelp-train.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0myelp_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './yelp-train.txt'"
     ]
    }
   ],
   "source": [
    "yelp_train_x = []\n",
    "yelp_train_y = []\n",
    "yelp_valid_x = []\n",
    "yelp_valid_y = []\n",
    "yelp_test_x = []\n",
    "yelp_test_y = []\n",
    "\n",
    "translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "\n",
    "with open('./yelp-train.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_train_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_train_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./yelp-valid.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_valid_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_valid_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./yelp-test.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_test_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_test_y.append(int(line[-2]))\n",
    "        \n",
    "wordfreq = {}\n",
    "\n",
    "\n",
    "def turntolist(data):\n",
    "    list_of_words =[]\n",
    "    for row in data:\n",
    "        words = row.split(\" \")\n",
    "        toadd = []\n",
    "        for word in words:\n",
    "            if word == ' ' or word == '':\n",
    "                continue\n",
    "            if word not in wordfreq:\n",
    "                wordfreq[word] = 1\n",
    "            else:\n",
    "                wordfreq[word] += 1\n",
    "            toadd.append(word)\n",
    "        list_of_words.append(toadd)\n",
    "    return list_of_words    \n",
    "    \n",
    "list_of_words_train = turntolist(yelp_train_x)\n",
    "list_of_words_valid = turntolist(yelp_valid_x)\n",
    "list_of_words_test = turntolist(yelp_test_x)\n",
    "\n",
    "\n",
    "sorted_wordfreq = sorted(wordfreq.items(), key=lambda x:x[1], reverse = True)[:10000]\n",
    "sorted_wordfreq_dict = dict(sorted(wordfreq.items(), key=lambda x:x[1], reverse = True)[:10000])     \n",
    "\n",
    "words = [k for (k,v) in sorted_wordfreq][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def bag_of_words_represntation(data):\n",
    "    DM_frequency = csr_matrix((0,10000))\n",
    "    DM_binary = csr_matrix((0,10000))\n",
    "    for j in data:\n",
    "        temp_freq = []\n",
    "        temp_binary = []\n",
    "        for word in words:\n",
    "            count = j.split(\" \").count(word)\n",
    "            temp_freq.append(count)\n",
    "            if count > 0:\n",
    "                temp_binary.append(1)\n",
    "            else:\n",
    "                temp_binary.append(count)\n",
    "        if sum(temp_freq) != 0:    \n",
    "            temp_freq = [i/sum(temp_freq) for i in temp_freq]        \n",
    "        temp_freq = csr_matrix(temp_freq)\n",
    "        temp_binary = csr_matrix(temp_binary)\n",
    "        DM_frequency = vstack((DM_frequency,temp_freq))\n",
    "        DM_binary = vstack((DM_binary,temp_binary))\n",
    "    return DM_frequency, DM_binary\n",
    "\n",
    "\n",
    "train_frequency_design, train_binary_design = bag_of_words_represntation(yelp_train_x)\n",
    "valid_frequency_design, valid_binary_design = bag_of_words_represntation(yelp_valid_x)\n",
    "test_frequency_design, test_binary_design = bag_of_words_represntation(yelp_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(train_frequency_design.toarray(), yelp_train_y)\n",
    "\n",
    "prediction__naive_valid = clf.predict(valid_binary_design)\n",
    "prediction_naives_test = clf.predict(test_binary_design)\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_frequency_design.toarray(), yelp_train_y)\n",
    "decision_valid_predict = decision_tree.predict(valid_binary_design)\n",
    "decision_test_predict = decision_tree.predict(test_binary_design)\n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_frequency_design.toarray(), yelp_train_y)\n",
    "svc_valid = lin_clf.predict(valid_binary_design)\n",
    "svc_test = lin_clf.predict(test_binary_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def out(prediction,outcome,k):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0    \n",
    "    \n",
    "    \n",
    "    for i in range(0,len(prediction)):\n",
    "        if (prediction[i] == k and outcome[i] ==k):\n",
    "            true_positive += 1\n",
    "        elif (prediction[i] == k and outcome[i] !=k):\n",
    "            false_positive += 1\n",
    "        elif (prediction[i] != k and outcome[i] ==k):\n",
    "            false_negative +=1\n",
    "        elif (prediction[i] != k and outcome[i] !=k):\n",
    "            true_negative += 1        \n",
    "            \n",
    "    positive.append((true_positive, false_positive))\n",
    "    negative.append((false_negative, true_negative))\n",
    "    \n",
    "    return positive,negative\n",
    "\n",
    "def performance(prediction, outcome):\n",
    "    true_positive_total = 0\n",
    "    false_positive_total = 0\n",
    "    true_negative_total = 0\n",
    "    false_negative_total = 0\n",
    "    pos = []\n",
    "    neg = []\n",
    "    for i in range(0,5):\n",
    "        temp_pos = out(prediction,outcome,i)[0]\n",
    "        temp_neg = out(prediction,outcome,i)[1]\n",
    "        true_positive_total += temp_pos[0][0]\n",
    "        false_positive_total += temp_pos[0][1]\n",
    "        false_negative_total += temp_neg[0][0]\n",
    "        true_negative_total += temp_neg[0][1]\n",
    "    pos.append((true_positive_total, false_positive_total))\n",
    "    neg.append((false_negative_total, true_negative_total))\n",
    "    return pos,neg\n",
    "        \n",
    "        \n",
    "        \n",
    "def measures(positive_values,negative_values):\n",
    "    accuracy = (positive_values[0])/(positive_values[0] + positive_values[1])\n",
    "    precision = (positive_values[0])/(positive_values[0] + positive_values[1])\n",
    "    recall = (positive_values[0])/(positive_values[0] + negative_values[0])\n",
    "    F_measure = 2*precision/(precision + recall)\n",
    "\n",
    "    \n",
    "    return accuracy,precision,recall,F_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9a6a110753c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpositive_binary_naives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_binary_naives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myelp_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpositive_binary_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_binary_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_test_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myelp_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpositive_binary_svc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_binary_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myelp_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'performance' is not defined"
     ]
    }
   ],
   "source": [
    "positive_binary_naives, negative_binary_naives = performance(prediction_test, yelp_test_y)\n",
    "positive_binary_tree, negative_binary_tree = performance(decision_test_predict, yelp_test_y)\n",
    "positive_binary_svc, negative_binary_svc = performance(svc_test, yelp_test_y)\n",
    "\n",
    "\n",
    "accuracy_binary_naives, precision_binary_naives, recall_binary_naives, F_measure_naives = measures(positive_binary_naives[0], negative_binary_naives[0])\n",
    "accuracy_binary_tree, precision_binary_tree, recall_binary_tree, F_measure_tree = measures(positive_binary_tree[0], negative_binary_tree[0])\n",
    "accuracy_binary_svc, precision_binary_svc, recall_binary_svc, F_measure_svc = measures(positive_binary_svc[0], negative_binary_svc[0])\n",
    "\n",
    "print(\"The accuracy of this tree_classifier is \" + str(100*accuracy_binary_tree) + \"%\")\n",
    "print(\"The precision of this tree_classifier is \" + str(100*precision_binary_tree) + \"%\")\n",
    "print(\"The recall of this tree_classifier is \" + str(100*recall_binary_tree) + \"%\")\n",
    "print(\"The F-measure of this tree_classifier is \" + str(F_measure_tree))\n",
    "\n",
    "print(\"The accuracy of this naives_classifier is \" + str(100*accuracy_binary_naives) + \"%\")\n",
    "print(\"The precision of this naives_classifier is \" + str(100*precision_binary_naives) + \"%\")\n",
    "print(\"The recall of this naives_classifier is \" + str(100*recall_binary_naives) + \"%\")\n",
    "print(\"The F-measure of this naives_classifier is \" + str(F_measure_naives) ) \n",
    "      \n",
    "\n",
    "print(\"The accuracy of this svc_classifier is \" + str(100*accuracy_binary_svc) + \"%\")\n",
    "print(\"The precision of this svc_classifier is \" + str(100*precision_binary_svc) + \"%\")\n",
    "print(\"The recall of this svc_classifier is \" + str(100*recall_binary_svc) + \"%\")\n",
    "print(\"The F-measure of this svc_classifier is \" + str(F_measure_svc))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 5 ... 5 5 3]\n"
     ]
    }
   ],
   "source": [
    "clf2 = GaussianNB()\n",
    "clf2.fit(train_frequency_design.toarray(), yelp_train_y)\n",
    "prediction_naives_test = clf2.predict(test_frequency_design.toarray())\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(DM_binary, yelp_train_y)\n",
    "decision_test_predict = decision_tree.predict(test_frequency_design)\n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_frequency_design.toarray(), yelp_train_y)\n",
    "svc_test = lin_clf.predict(test_frequency_design.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this tree_classifier is 7.1499999999999995%\n",
      "The precision of this tree_classifier is 7.1499999999999995%\n",
      "The recall of this tree_classifier is 10.711610486891386%\n",
      "The F-measure of this tree_classifier is 0.800599700149925\n",
      "The accuracy of this naives_classifier is 28.195763330898465%\n",
      "The precision of this naives_classifier is 28.195763330898465%\n",
      "The recall of this naives_classifier is 28.91385767790262%\n",
      "The F-measure of this naives_classifier is 0.9874260355029587\n",
      "The accuracy of this svc_classifier is 41.50787075393538%\n",
      "The precision of this svc_classifier is 41.50787075393538%\n",
      "The recall of this svc_classifier is 37.52808988764045%\n",
      "The F-measure of this svc_classifier is 1.050354051927616\n"
     ]
    }
   ],
   "source": [
    "positive_frequency_naives, negative_frequency_naives = performance(prediction_naives_test, yelp_test_y)\n",
    "positive_frequency_tree, negative_frequency_tree = performance(decision_test_predict, yelp_test_y)\n",
    "positive_frequency_svc, negative_frequency_svc = performance(svc_test, yelp_test_y)\n",
    "\n",
    "\n",
    "accuracy_frequency_naives, precision_frequency_naives, recall_frequency_naives, F_measure_naives = measures(positive_frequency_naives[0], negative_frequency_naives[0])\n",
    "accuracy_frequency_tree, precision_frequency_tree, recall_frequency_tree, F_measure_tree = measures(positive_frequency_tree[0], negative_frequency_tree[0])\n",
    "accuracy_frequency_svc, precision_frequency_svc, recall_frequency_svc, F_measure_svc = measures(positive_frequency_svc[0], negative_frequency_svc[0])\n",
    "\n",
    "\n",
    "print(\"The accuracy of this tree_classifier is \" + str(100*accuracy_frequency_tree) + \"%\")\n",
    "print(\"The precision of this tree_classifier is \" + str(100*precision_frequency_tree) + \"%\")\n",
    "print(\"The recall of this tree_classifier is \" + str(100*recall_frequency_tree) + \"%\")\n",
    "print(\"The F-measure of this tree_classifier is \" + str(F_measure_tree) ) \n",
    "      \n",
    "print(\"The accuracy of this naives_classifier is \" + str(100*accuracy_frequency_naives) + \"%\")\n",
    "print(\"The precision of this naives_classifier is \" + str(100*precision_frequency_naives) + \"%\")\n",
    "print(\"The recall of this naives_classifier is \" + str(100*recall_frequency_naives) + \"%\")\n",
    "print(\"The F-measure of this naives_classifier is \" + str(F_measure_naives))\n",
    "\n",
    "print(\"The accuracy of this svc_classifier is \" + str(100*accuracy_frequency_svc) + \"%\")\n",
    "print(\"The precision of this svc_classifier is \" + str(100*precision_frequency_svc) + \"%\")\n",
    "print(\"The recall of this svc_classifier is \" + str(100*recall_frequency_svc) + \"%\")\n",
    "print(\"The F-measure of this svc_classifier is \" + str(F_measure_svc))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMDB_train_x = []\n",
    "IMDB_train_y = []\n",
    "IMDB_valid_x = []\n",
    "IMDB_valid_y = []\n",
    "IMDB_test_x = []\n",
    "IMDB_test_y = []\n",
    "\n",
    "translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "\n",
    "with open('./IMDB-train.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_train_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_train_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./IMDB-valid.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_valid_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_valid_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./IMDB-test.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_test_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_test_y.append(int(line[-2]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
