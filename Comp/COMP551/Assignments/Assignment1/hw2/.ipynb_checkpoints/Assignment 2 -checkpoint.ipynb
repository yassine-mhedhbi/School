{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read the first vector.\n",
    "data = open('DS1_m_0.txt','r').readline()\n",
    "d = data.split(',')\n",
    "d.remove('\\n')\n",
    "data_0 = [float(s) for s in d]\n",
    "#print(data_0)\n",
    "\n",
    "# read the 2nd one\n",
    "data = open('DS1_m_1.txt','r').readline()\n",
    "d = data.split(',')\n",
    "d.remove('\\n')\n",
    "data_1 = [float(s) for s in d]\n",
    "#print(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will write a function that calculate the best fit\n",
    "def c(a):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    for i in a:\n",
    "        if (i > 0):\n",
    "            p = p + 1\n",
    "        else:\n",
    "            n = n + 1\n",
    "    return positive, negative\n",
    "\n",
    "# lecture 8 formulas,\n",
    "def best_fit(a,b):\n",
    "    \n",
    "    \n",
    "    accuracy = (c(a)[0] + c(b)[1])/1200\n",
    "    precision = (c(a)[0])/(c(a)[0] + c(b)[1])\n",
    "    recall = (c(a)[0])/(c(a)[0] + c(b)[0])\n",
    "    F = 2*precision/(precision + recall)\n",
    "    return accuracy, precision, recall, F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov = []\n",
    "with open('DS1_Cov.txt','r') as file:\n",
    "    for line in file:\n",
    "        #read the row\n",
    "        r = line.split(',')\n",
    "        r.remove('\\n')\n",
    "        row = [float(s) for s in r]\n",
    "        #add it to the matrix\n",
    "        cov = cov + [row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative = np.random.multivariate_normal(data_0,cov,2000)\n",
    "positive = np.random.multivariate_normal(data_1,cov,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "#Get the test and training data.\n",
    "random.shuffle(negative)\n",
    "Train_0 = negative[:1400]\n",
    "Test_0  = negative[1400:]\n",
    "\n",
    "random.shuffle(positive)\n",
    "Train_1 = positive[:1400]\n",
    "Test_1  = positive[1400:]\n",
    "\n",
    "DS1 = np.concatenate((Test_0, Test_1), axis=0)\n",
    "\n",
    "random.shuffle(DS1)\n",
    "file = open('DS1.txt', 'w')\n",
    "for x in DS1:\n",
    "    file.write(\"%s\\n\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First maximization, we calcualte the means (pi is 1/2 obviously)\n",
    "\n",
    "M0 = np.mean(Train_0, axis=0)\n",
    "M1 = np.mean(Train_1, axis=0)\n",
    "\n",
    "#print(Train_1)\n",
    "#print(\"---------------\")\n",
    "#print(Train_0)\n",
    "# now the covariance maximization.\n",
    "# first calculate s1/N\n",
    "s1 = np.zeros((20,20))\n",
    "for x in Train_0:\n",
    "    x = np.subtract(x,M0)\n",
    "    b = np.array(x).T\n",
    "    A = b.reshape(-1,1)\n",
    "    B = np.dot(A,[x] )\n",
    "    s1 = np.add(s1, B)\n",
    "s1 = np.divide(s1,2800)\n",
    "\n",
    "# now s2/N\n",
    "s2 = np.zeros((20,20))\n",
    "for x in Train_1:\n",
    "    x = np.subtract(x,M1)\n",
    "    b = np.array(x).T\n",
    "    A = b.reshape(-1,1)\n",
    "    B = np.dot(A,[x] )\n",
    "    s2 = np.add(s2, B)\n",
    "s2 = np.divide(s2,2800)\n",
    "\n",
    "# getting the covariance\n",
    "COV = np.add(s1,s2)\n",
    "#print(M1)\n",
    "#print(M0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now to get the parameters W0 and W\n",
    "# we start first with W\n",
    "E_1 = np.linalg.inv(COV)\n",
    "W = np.dot(E_1, ( np.subtract(M0,M1) ) )\n",
    "\n",
    "# now for W0\n",
    "M0_t = M0.reshape(-1,1)\n",
    "A = np.dot(M0,E_1)\n",
    "A = np.dot(A,M0_t)\n",
    "A = np.dot(-1/2,A)\n",
    "\n",
    "M1_t = M1.reshape(-1,1)\n",
    "B = np.dot(M1,E_1)\n",
    "B = np.dot(B,M1_t)\n",
    "B = np.dot(1/2,B)\n",
    "\n",
    "W0 = A[0]+B[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this classifier is  0.9483333333333334\n",
      "The precision of this classifier is  0.9566666666666667\n",
      "The recall of this classifier is  0.940983606557377\n",
      "The F-measure of this classifier is  1.0082644628099173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now for testing !!\n",
    "\n",
    "def classify(W,W0,x):\n",
    "    a = np.dot(W.T,x) + W0\n",
    "    res = 1/(1+np.exp(-a))\n",
    "    if res > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "# Performance test\n",
    "DS1, Test_0, Test_1\n",
    "\n",
    "p = np.matmul(Test_0,W) + W0\n",
    "n = np.matmul(Test_1,W) + W0\n",
    "\n",
    "\n",
    "def c(a):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    for i in a:\n",
    "        if (i > 0):\n",
    "            p = p + 1\n",
    "        else:\n",
    "            n = n + 1\n",
    "    return positive, negative\n",
    "\n",
    "score = 0\n",
    "for t in DS1:\n",
    "    v = classify(W, W0, t)\n",
    "    if v == 1 :\n",
    "        score = score + 1\n",
    "    elif v == 2:\n",
    "        score = score +1 \n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "accuracy = (c(p)[0] + c(n)[1])/1200\n",
    "precision = (c(p)[0])/(c(p)[0] + c(p)[1])\n",
    "recall = (c(p)[0])/(c(p)[0] + c(n)[0])\n",
    "\n",
    "\n",
    "\n",
    "print(\"The accuracy of this classifier is \" ,accuracy)\n",
    "print(\"The precision of this classifier is \" ,precision) \n",
    "print(\"The recall of this classifier is \" ,recall) \n",
    "print(\"The F-measure of this classifier is \" ,2*precision/(precision + recall))\n",
    "\n",
    "\n",
    "score/1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 K-NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this classifier is  0.5\n",
      "The precision of this classifier is  0.335\n",
      "The recall of this classifier is  0.5\n",
      "The F-measure of this classifier is  0.8023952095808384\n",
      "The best k value is: 3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import operator\n",
    "# now we write a function that calculate euclidien distance\n",
    "def Dis(x1,x2):\n",
    "    res = 0\n",
    "    for i in range(len(x1)):\n",
    "        res += pow((x1[i] - x2[i]), 2)\n",
    "    return math.sqrt(res)\n",
    "\n",
    "\n",
    "def knearestneighbourhood(train,point,k):\n",
    "    distances = []\n",
    "    length = len(train)\n",
    "    for x in range(0,length):\n",
    "        dist = Dis(point,X[x])\n",
    "        if (x < length/2):\n",
    "            distances.append((dist,1))\n",
    "        else:\n",
    "            distances.append((dist,0))\n",
    "    distances = sorted(distances)[:k]\n",
    "    frequency_p = 0\n",
    "    frequency_n = 0 \n",
    "    \n",
    "    for dist in distances:\n",
    "        if dist[1] == 0:\n",
    "            frequency_n += 1\n",
    "        elif dist[1] == 1:\n",
    "            frequency_p += 1\n",
    "    return 0 if frequency_n>frequency_p else 1\n",
    "def getresultk(test,train,k):\n",
    "    out = []\n",
    "    for i in test:\n",
    "        out.append(knearestneighbourhood(train,i,k))\n",
    "    return out\n",
    "\n",
    "\n",
    "def best_fit_KNN(positive_values,negative_values):\n",
    "    \n",
    "    highest_f_measure = -1\n",
    "    index = 0\n",
    "    for i in range(0,len(positive_values)):\n",
    "        accuracy = (positive_values[i][0] + negative_values[i][1])/1200\n",
    "        precision = (positive_values[i][0])/(positive_values[i][0] + positive_values[i][1])\n",
    "        recall = (positive_values[i][0])/(positive_values[i][0] + negative_values[i][0])\n",
    "        F_measure = 2*precision/(precision + recall)\n",
    "        if (F_measure > highest_f_measure):\n",
    "            highest_f_measure = F_measure\n",
    "            index = i\n",
    "    accuracy = (positive_values[index][0] + negative_values[index][1])/1200\n",
    "    precision = (positive_values[index][0])/(positive_values[index][0] + positive_values[index][1])\n",
    "    recall = (positive_values[index][0])/(positive_values[index][0] + negative_values[index][0])\n",
    "    F_measure = 2*precision/(precision + recall)\n",
    "    \n",
    "    return accuracy,precision,recall,F_measure,index\n",
    "\n",
    "\n",
    "TrainingSet = np.concatenate((Train_0, Train_1), axis=0)\n",
    "\n",
    "random.shuffle(TrainingSet)\n",
    "def best_fit_KNN(positive_values,negative_values):\n",
    "    \n",
    "    highest_f_measure = -1\n",
    "    index = 0\n",
    "    for i in range(0,len(positive_values)):\n",
    "        accuracy = (positive_values[i][0] + negative_values[i][1])/1200\n",
    "        precision = (positive_values[i][0])/(positive_values[i][0] + positive_values[i][1])\n",
    "        recall = (positive_values[i][0])/(positive_values[i][0] + negative_values[i][0])\n",
    "        F_measure = 2*precision/(precision + recall)\n",
    "        if (F_measure > highest_f_measure):\n",
    "            highest_f_measure = F_measure\n",
    "            index = i\n",
    "    accuracy = (positive_values[index][0] + negative_values[index][1])/1200\n",
    "    precision = (positive_values[index][0])/(positive_values[index][0] + positive_values[index][1])\n",
    "    recall = (positive_values[index][0])/(positive_values[index][0] + negative_values[index][0])\n",
    "    F_measure = 2*precision/(precision + recall)\n",
    "    \n",
    "    return accuracy,precision,recall,F_measure,index\n",
    "\n",
    "X=list(TrainingSet)\n",
    "positive_values = []\n",
    "negative_values = []\n",
    "\n",
    "# we try diff values for k\n",
    "for k in range(1,8):\n",
    "    sample1 = getresultk(Test_0, Train_0,k)\n",
    "    sample2 = getresultk(Test_1, Train_1,k)\n",
    "    positive_values.append(count(sample1))\n",
    "    negative_values.append(count(sample2))\n",
    "\n",
    "c,d,e,f,k = best_fit_KNN(positive_values,positive_values)\n",
    "print(\"The accuracy of this classifier is \",c)\n",
    "print(\"The precision of this classifier is \",d)\n",
    "print(\"The recall of this classifier is \",e)\n",
    "print(\"The F-measure of this classifier is \",f)\n",
    "print(\"The best k value is:\",k)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "probability = [0.1,0.42,0.48]\n",
    "def param(Cov,M0,M1):\n",
    "    E_1 = np.linalg.inv(Cov)\n",
    "    W = np.dot(E_1, ( np.subtract(M0,M1) ) )\n",
    "    # now for W0\n",
    "    M0_t = M0.reshape(-1,1)\n",
    "    A = np.dot(M0,E_1)\n",
    "    A = np.dot(A,M0_t)\n",
    "    A = np.dot(-1/2,A)\n",
    "\n",
    "    M1_t = M1.reshape(-1,1)\n",
    "    B = np.dot(M1,E_1)\n",
    "    B = np.dot(B,M1_t)\n",
    "    B = np.dot(1/2,B)\n",
    "    W0 = A[0]+B[0]\n",
    "    \n",
    "    return W,W0\n",
    "\n",
    "def split(data):\n",
    "    np.random.shuffle(data)\n",
    "    test = []\n",
    "    train = []\n",
    "    for row in data[0:600]:\n",
    "        test.append(row)\n",
    "    \n",
    "    for row in data[600:2001]:\n",
    "        train.append(row)\n",
    "        \n",
    "    return test,train\n",
    "\n",
    "def classify(W,W0,x):\n",
    "    a = np.dot(W.T,x) + W0\n",
    "    res = 1/(1+np.exp(-a))\n",
    "    if res > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "\n",
    "ds2c1m1 = np.genfromtxt(\"DS2_c1_m1.txt\", delimiter=',')\n",
    "ds2c1m2 = np.genfromtxt(\"DS2_c1_m2.txt\", delimiter=',')\n",
    "ds2c1m3 = np.genfromtxt(\"DS2_c1_m3.txt\", delimiter=',')\n",
    "\n",
    "ds2c2m1 = np.genfromtxt(\"DS2_c2_m1.txt\", delimiter=',')\n",
    "ds2c2m2 = np.genfromtxt(\"DS2_c2_m2.txt\", delimiter=',')\n",
    "ds2c2m3 = np.genfromtxt(\"DS2_c2_m3.txt\", delimiter=',')\n",
    "\n",
    "ds2cov1 = np.genfromtxt(\"DS2_Cov1.txt\", delimiter=',')\n",
    "ds2cov2 = np.genfromtxt(\"DS2_Cov2.txt\", delimiter=',')\n",
    "ds2cov3 = np.genfromtxt(\"DS2_Cov3.txt\", delimiter=',')\n",
    "\n",
    "ds2c1m1=ds2c1m1[:20]\n",
    "ds2c1m2=ds2c1m2[:20]\n",
    "ds2c1m3=ds2c1m3[:20]\n",
    "ds2c2m1=ds2c2m1[:20]\n",
    "ds2c2m2=ds2c2m2[:20]\n",
    "ds2c2m3=ds2c2m3[:20]\n",
    "ds2cov1=ds2cov1[:,:20]\n",
    "ds2cov2=ds2cov2[:,:20]\n",
    "ds2cov3=ds2cov3[:,:20]\n",
    "\n",
    "\n",
    "\n",
    "sampling1 = np.random.multinomial(2000,probability)\n",
    "sampling2 = np.random.multinomial(2000,probability)\n",
    "\n",
    "class1_m1 = np.random.multivariate_normal(ds2c1m1,ds2cov1, sampling1[0])\n",
    "class1_m2 = np.random.multivariate_normal(ds2c1m2,ds2cov2, sampling1[1])\n",
    "class1_m3 = np.random.multivariate_normal(ds2c1m3,ds2cov3, sampling1[2])\n",
    "class2_m1 = np.random.multivariate_normal(ds2c1m1,ds2cov1, sampling1[0])\n",
    "class2_m2 = np.random.multivariate_normal(ds2c1m2,ds2cov2, sampling1[1])\n",
    "class2_m3 = np.random.multivariate_normal(ds2c1m3,ds2cov3, sampling1[2])\n",
    "\n",
    "# Append list to form a class.\n",
    "positive2 = list(class1_m1)\n",
    "positive2.extend(list(class1_m2))\n",
    "positive2.extend(list(class1_m3))\n",
    "\n",
    "negative2 = list(class2_m1)\n",
    "negative2.extend(list(class2_m2))\n",
    "negative2.extend(list(class2_m3))\n",
    "\n",
    "q4_test1, q4_train1 = split(positive2)\n",
    "q4_test2, q4_train2 = split(negative2)\n",
    "\n",
    "TrainingSet = np.concatenate((q4_train1, q4_train2), axis=0)\n",
    "Test = np.concatenate((q4_test1, q4_test2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this classifier is  0.4841666666666667\n",
      "The precision of this classifier is  0.4819277108433735\n",
      "The recall of this classifier is  0.4835924006908463\n",
      "The F-measure of this classifier is  0.9982758620689655\n"
     ]
    }
   ],
   "source": [
    "# now repeating the experiments 2 and 3.\n",
    "\n",
    "\n",
    "M0 = np.mean(q4_train1, axis=0)\n",
    "M1 = np.mean(q4_train2, axis=0)\n",
    "\n",
    "s1 = np.zeros((20,20))\n",
    "for x in q4_train1:\n",
    "    x = np.subtract(x,M0)\n",
    "    b = np.array(x).T\n",
    "    A = b.reshape(-1,1)\n",
    "    B = np.dot(A,[x] )\n",
    "    s1 = np.add(s1, B)\n",
    "s1 = np.divide(s1,2800)\n",
    "\n",
    "# now s2/N\n",
    "s2 = np.zeros((20,20))\n",
    "for x in q4_train2:\n",
    "    x = np.subtract(x,M1)\n",
    "    b = np.array(x).T\n",
    "    A = b.reshape(-1,1)\n",
    "    B = np.dot(A,[x] )\n",
    "    s2 = np.add(s2, B)\n",
    "s2 = np.divide(s2,2800)\n",
    "def Dis(x1,x2):\n",
    "    res = 0\n",
    "    for i in range(len(x1)):\n",
    "        res += pow((x1[i] - x2[i]), 2)\n",
    "    return math.sqrt(res)\n",
    "\n",
    "def knearestneighbourhood(train,point,k):\n",
    "    distances = []\n",
    "    length = len(train)\n",
    "    for x in range(0,length):\n",
    "        dist = Dis(point,train[x])\n",
    "        if (x < length/2):\n",
    "            distances.append((dist,1))\n",
    "        else:\n",
    "            distances.append((dist,0))\n",
    "    distances = sorted(distances)[:k]\n",
    "    frequency_p = 0\n",
    "    frequency_n = 0 \n",
    "    \n",
    "    for dist in distances:\n",
    "        if dist[1] == 0:\n",
    "            frequency_n += 1\n",
    "        elif dist[1] == 1:\n",
    "            frequency_p += 1\n",
    "    return 0 if frequency_n>frequency_p else 1\n",
    "def getresultk(test,train,k):\n",
    "    out = []\n",
    "    for i in test:\n",
    "        out.append(knearestneighbourhood(train,i,k))\n",
    "    return out\n",
    "\n",
    "# getting the covariance\n",
    "COV = np.add(s1,s2)\n",
    "#print(M0,M1)\n",
    "W,W0 = param(COV, M0, M1 )\n",
    "\n",
    "a = np.matmul(q4_test1,W) + W0\n",
    "b = np.matmul(q4_test2,W) + W0\n",
    "\n",
    "c,d,e,f = best_fit(a,b)\n",
    "\n",
    "print(\"The accuracy of this classifier is \",c)\n",
    "print(\"The precision of this classifier is \",d)\n",
    "print(\"The recall of this classifier is \",e)\n",
    "print(\"The F-measure of this classifier is \",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c =[]\n",
    "d =[]\n",
    "e =[]\n",
    "f =[]\n",
    "pos = []\n",
    "neg = []\n",
    "\n",
    "X=list(q4_train1)\n",
    "positive_values = []\n",
    "negative_values = []\n",
    "\n",
    "# we try diff values for k\n",
    "for k in range(1,8):\n",
    "    sample1 = getresultk(q4_test1, q4_train1,k)\n",
    "    sample2 = getresultk(q4_test2, q4_train2,k)\n",
    "    positive_values.append(count(sample1))\n",
    "    negative_values.append(count(sample2))\n",
    "    \n",
    "\n",
    "def best_fit_KNN(positive_values,negative_values):\n",
    "    \n",
    "    highest_f_measure = -1\n",
    "    index = 0\n",
    "    for i in range(0,len(positive_values)):\n",
    "        accuracy = (positive_values[i][0] + negative_values[i][1])/1200\n",
    "        precision = (positive_values[i][0])/(positive_values[i][0] + positive_values[i][1])\n",
    "        recall = (positive_values[i][0])/(positive_values[i][0] + negative_values[i][0])\n",
    "        F_measure = 2*precision/(precision + recall)\n",
    "        if (F_measure > highest_f_measure):\n",
    "            highest_f_measure = F_measure\n",
    "            index = i\n",
    "    accuracy = (positive_values[index][0] + negative_values[index][1])/1200\n",
    "    precision = (positive_values[index][0])/(positive_values[index][0] + positive_values[index][1])\n",
    "    recall = (positive_values[index][0])/(positive_values[index][0] + negative_values[index][0])\n",
    "    F_measure = 2*precision/(precision + recall)\n",
    "    \n",
    "    return accuracy,precision,recall,F_measure,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this classifier is  0.5\n",
      "The precision of this classifier is  0.765\n",
      "The recall of this classifier is  0.5\n",
      "The F-measure of this classifier is  1.209486166007905\n",
      "The best k value is: 1\n"
     ]
    }
   ],
   "source": [
    "def best_fit_KNN(positive_values,negative_values):\n",
    "    \n",
    "    highest_f_measure = -1\n",
    "    index = 0\n",
    "    for i in range(0,len(positive_values)):\n",
    "        accuracy = (positive_values[i][0] + negative_values[i][1])/1200\n",
    "        precision = (positive_values[i][0])/(positive_values[i][0] + positive_values[i][1])\n",
    "        recall = (positive_values[i][0])/(positive_values[i][0] + negative_values[i][0])\n",
    "        F_measure = 2*precision/(precision + recall)\n",
    "        if (F_measure > highest_f_measure):\n",
    "            highest_f_measure = F_measure\n",
    "            index = i\n",
    "    accuracy = (positive_values[index][0] + negative_values[index][1])/1200\n",
    "    precision = (positive_values[index][0])/(positive_values[index][0] + positive_values[index][1])\n",
    "    recall = (positive_values[index][0])/(positive_values[index][0] + negative_values[index][0])\n",
    "    F_measure = 2*precision/(precision + recall)\n",
    "    \n",
    "    return accuracy,precision,recall,F_measure,index\n",
    "\n",
    "\n",
    "\n",
    "c,d,e,f,k = best_fit_KNN(positive_values,positive_values)\n",
    "print(\"The accuracy of this classifier is \",c)\n",
    "print(\"The precision of this classifier is \",d)\n",
    "print(\"The recall of this classifier is \",e)\n",
    "print(\"The F-measure of this classifier is \",f)\n",
    "print(\"The best k value is:\",k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
