{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from numpy.linalg import inv\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "\n",
    "\n",
    "cov = []\n",
    "mean0 = []\n",
    "mean1 = []\n",
    "with open('./data/DS1_Cov.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        cov.append(to_add)\n",
    "\n",
    "with open('./data/DS1_m_0.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        mean0.append(to_add)\n",
    "\n",
    "        \n",
    "with open('./data/DS1_m_1.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        mean1.append(to_add)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = np.random.multivariate_normal(mean1[0],cov, 2000)\n",
    "negative = np.random.multivariate_normal(mean0[0],cov, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(data_array):\n",
    "    np.random.shuffle(data_array)\n",
    "    test_set = []\n",
    "    train_set = []\n",
    "    for row in data_array[0:600]:\n",
    "        test_set.append(row)\n",
    "    \n",
    "    for row in data_array[600:2001]:\n",
    "        train_set.append(row)\n",
    "        \n",
    "    return test_set,train_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1,train1 = sampling(positive)\n",
    "t_1 = [1 for i in range(0,1400)]\n",
    "test2,train2 = sampling(negative)\n",
    "t_0 = [0 for i in range(0,1400)]\n",
    "X=list(train1)\n",
    "#t = t_1\n",
    "#t.extend(t_2)\n",
    "X.extend(train2)\n",
    "def MLE_estimator(train1, train2, t_0,t_1):\n",
    "    MLE_mean0 = (1/len(t_0))*(np.matmul(np.transpose(train1),t_0))\n",
    "    MLE_mean1 = (1/len(t_1))*(np.matmul(np.transpose(train2),t_1))\n",
    "    pi = len(t_1)/(len(t_1) + len(t_0))\n",
    "    S_1 = 1/(len(t_1)) * (np.matmul(np.transpose([(i - mean1)[0] for i in train1]),([(i - mean1)[0] for i in train1])))\n",
    "    #S_1 = positive\n",
    "    S_2 = 1/(len(t_1)) * (np.matmul(np.transpose([(i - mean0)[0] for i in train2]), [(i - mean0)[0] for i in train2]))\n",
    "\n",
    "    sigma = (len(t_1)/(len(t_1) + len(t_0)))*S_1 + (len(t_0)/(len(t_1) + len(t_0)))*S_2\n",
    "    \n",
    "    omega = np.matmul(inv(sigma), np.transpose(np.subtract(mean1, mean0)))\n",
    "    omega0 = (-1/2)*np.matmul(np.matmul(mean1,inv(sigma)),np.transpose(mean1)) + (1/2)*np.matmul(np.matmul(mean0,inv(sigma)),np.transpose(mean0))\n",
    "    return omega0,omega\n",
    "\n",
    "q2_omega0,q2_omega = MLE_estimator(train1,train2, t_0, t_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If entries are negative then, we know that probability of it being positive is less than $\\frac{1}{2}$, if entries are positive, the probabilitiy is greater than $\\frac{1}{2}$. Hence we can select for positive and negative entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575, 25)\n",
      "(27, 573)\n",
      "The accuracy of this classifier is 95.66666666666667%\n",
      "The precision of this classifier is 95.83333333333334%\n",
      "The recall of this classifier is 95.51495016611295%\n",
      "The F-measure of this classifier is 1.0016638935108153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1 = np.matmul(test1,q2_omega) + q2_omega0\n",
    "pred2 = np.matmul(test2,q2_omega) + q2_omega0\n",
    "\n",
    "\n",
    "def count(mat):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for i in mat:\n",
    "        if (i > 0):\n",
    "            positive +=1\n",
    "        else:\n",
    "            negative +=1\n",
    "    return positive, negative\n",
    "print(count(pred1))\n",
    "print(count(pred2))\n",
    "\n",
    "accuracy = (count(pred1)[0] + count(pred2)[1])/1200\n",
    "precision = (count(pred1)[0])/(count(pred1)[0] + count(pred1)[1])\n",
    "recall = (count(pred1)[0])/(count(pred1)[0] + count(pred2)[0])\n",
    "\n",
    "\n",
    "\n",
    "print(\"The accuracy of this classifier is \" + str(100*accuracy) + \"%\")\n",
    "print(\"The precision of this classifier is \" + str(100*precision) + \"%\")\n",
    "print(\"The recall of this classifier is \" + str(100*recall) + \"%\")\n",
    "print(\"The F-measure of this classifier is \" + str(2*precision/(precision + recall)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(vector1, vector2):\n",
    "    out = 0\n",
    "    for i in range(0,len(vector1)):\n",
    "        out += pow((vector1[i] - vector2[i]),2)\n",
    "    return math.sqrt(out)\n",
    "\n",
    "def knearestneighbourhood(train,point,k):\n",
    "    distances = []\n",
    "    length = len(train)\n",
    "    for x in range(0,length):\n",
    "        dist = distance(point,X[x])\n",
    "        if (x < length/2):\n",
    "            distances.append((dist,1))\n",
    "        else:\n",
    "            distances.append((dist,0))\n",
    "    distances = sorted(distances)[:k]\n",
    "    frequency_p = 0\n",
    "    frequency_n = 0 \n",
    "    \n",
    "    for dist in distances:\n",
    "        if dist[1] == 0:\n",
    "            frequency_n += 1\n",
    "        elif dist[1] == 1:\n",
    "            frequency_p += 1\n",
    "    return 0 if frequency_n>frequency_p else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultsknearest(test,train,k):\n",
    "    out = []\n",
    "    for i in test:\n",
    "        out.append(knearestneighbourhood(train,i,k))\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_values = []\n",
    "negative_values = []\n",
    "for k in range(1,13):\n",
    "    sample1 = resultsknearest(test1, train1,k)\n",
    "    sample2 = resultsknearest(test2, train2,k)\n",
    "    positive_values.append(count(sample1))\n",
    "    negative_values.append(count(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(312, 288), (462, 138), (321, 279), (416, 184), (325, 275), (409, 191), (319, 281), (396, 204), (314, 286), (388, 212), (323, 277), (386, 214)]\n",
      "[(315, 285), (475, 125), (297, 303), (422, 178), (308, 292), (398, 202), (294, 306), (392, 208), (306, 294), (375, 225), (310, 290), (370, 230)]\n",
      "value of k that performs the best is  1\n",
      "The accuracy of this classifier is 48.91666666666667%\n",
      "The precision of this classifier is 77.0%\n",
      "The recall of this classifier is 49.30629669156883%\n",
      "The F-measure of this classifier is 1.2192582953806117\n"
     ]
    }
   ],
   "source": [
    "print(positive_values)\n",
    "print(negative_values)\n",
    "def best_fit(positive_values,negative_values):\n",
    "    \n",
    "    highest_f_measure = -1\n",
    "    index = 0\n",
    "    for i in range(0,len(positive_values)):\n",
    "        accuracy = (positive_values[i][0] + negative_values[i][1])/1200\n",
    "        precision = (positive_values[i][0])/(positive_values[i][0] + positive_values[i][1])\n",
    "        recall = (positive_values[i][0])/(positive_values[i][0] + negative_values[i][0])\n",
    "        F_measure = 2*precision/(precision + recall)\n",
    "        if (F_measure > highest_f_measure):\n",
    "            highest_f_measure = F_measure\n",
    "            index = i\n",
    "    accuracy = (positive_values[index][0] + negative_values[index][1])/1200\n",
    "    precision = (positive_values[index][0])/(positive_values[index][0] + positive_values[index][1])\n",
    "    recall = (positive_values[index][0])/(positive_values[index][0] + negative_values[index][0])\n",
    "    F_measure = 2*precision/(precision + recall)\n",
    "    \n",
    "    return accuracy,precision,recall,F_measure,index\n",
    "\n",
    "accuracy,precision,recall,F_measure,index = best_fit(positive_values,negative_values)\n",
    "print(\"value of k that performs the best is \", index)\n",
    "\n",
    "print(\"The accuracy of this classifier is \" + str(100*accuracy) + \"%\")\n",
    "print(\"The precision of this classifier is \" + str(100*precision) + \"%\")\n",
    "print(\"The recall of this classifier is \" + str(100*recall) + \"%\")\n",
    "print(\"The F-measure of this classifier is \" + str(2*precision/(precision + recall)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_cov1 = []\n",
    "q4_cov2 = []\n",
    "q4_cov3 = []\n",
    "q4_c1_mean1 = []\n",
    "q4_c1_mean2 = []\n",
    "q4_c1_mean3 = []\n",
    "q4_c2_mean1 = []\n",
    "q4_c2_mean2 = []\n",
    "q4_c2_mean3 = []\n",
    "probability = [0.1,0.42,0.48]\n",
    "\n",
    "with open('./data/DS2_Cov1.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_cov1.append(to_add)\n",
    "with open('./data/DS2_Cov2.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_cov2.append(to_add)\n",
    "with open('./data/DS2_Cov3.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_cov3.append(to_add)      \n",
    "with open('./data/DS2_c1_m1.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_c1_mean1.append(to_add)\n",
    "with open('./data/DS2_c1_m2.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_c1_mean2.append(to_add)\n",
    "with open('./data/DS2_c1_m3.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_c1_mean3.append(to_add)\n",
    "with open('./data/DS2_c2_m1.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_c2_mean1.append(to_add)\n",
    "with open('./data/DS2_c2_m2.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_c2_mean2.append(to_add)        \n",
    "with open('./data/DS2_c2_m3.txt') as f:\n",
    "    for line in f:\n",
    "        to_add = line.split(',')\n",
    "        to_add = [float(i) for i in to_add[0:len(to_add) - 1]]\n",
    "        q4_c2_mean3.append(to_add)        \n",
    "        \n",
    "sampling1 = np.random.multinomial(2000,probability)\n",
    "sampling2 = np.random.multinomial(2000,probability)\n",
    "class1_m1 = np.random.multivariate_normal(q4_c1_mean1[0],q4_cov1, sampling1[0])\n",
    "class1_m2 = np.random.multivariate_normal(q4_c1_mean2[0],q4_cov2, sampling1[1])\n",
    "class1_m3 = np.random.multivariate_normal(q4_c1_mean3[0],q4_cov3, sampling1[2])\n",
    "class2_m1 = np.random.multivariate_normal(q4_c2_mean1[0],q4_cov1, sampling1[0])\n",
    "class2_m2 = np.random.multivariate_normal(q4_c2_mean2[0],q4_cov2, sampling1[1])\n",
    "class2_m3 = np.random.multivariate_normal(q4_c2_mean3[0],q4_cov3, sampling1[2])\n",
    "positive2 = list(class1_m1)\n",
    "positive2.extend(list(class1_m2))\n",
    "positive2.extend(list(class1_m3))\n",
    "negative2 = list(class2_m1)\n",
    "negative2.extend(list(class2_m2))\n",
    "negative2.extend(list(class2_m3))\n",
    "\n",
    "q5_test1, q5_train1 = sampling(positive2)\n",
    "q5_t1 = [1 for i in range(0,1400)]\n",
    "q5_test2, q5_train2 = sampling(negative2)\n",
    "q5_t2 = [0 for i in range(0,1400)]\n",
    "\n",
    "q5_omega0, q5_omega = MLE_estimator(q5_train1,q5_train2,q5_t1, q5_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q5_pred1 = np.matmul(q5_test1,q5_omega) + q5_omega0\n",
    "q5_pred2 = np.matmul(q5_test2,q5_omega) + q5_omega0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 391)\n",
      "(222, 378)\n"
     ]
    }
   ],
   "source": [
    "print(count(q5_pred1))\n",
    "print(count(q5_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_positive_values = []\n",
    "q5_negative_values = []\n",
    "for k in range(1,13):\n",
    "    sample1 = resultsknearest(q5_test1, q5_train1,k)\n",
    "    sample2 = resultsknearest(q5_test2, q5_train2,k)\n",
    "    q5_positive_values.append(count(sample1))\n",
    "    q5_negative_values.append(count(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(298, 302), (444, 156), (287, 313), (403, 197), (306, 294), (391, 209), (299, 301), (384, 216), (299, 301), (370, 230), (310, 290), (372, 228)]\n",
      "[(302, 298), (454, 146), (292, 308), (424, 176), (295, 305), (405, 195), (309, 291), (409, 191), (319, 281), (392, 208), (318, 282), (385, 215)]\n"
     ]
    }
   ],
   "source": [
    "print(q5_positive_values)\n",
    "print(q5_negative_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of k that performs the best is  1\n",
      "The accuracy of this classifier is 49.166666666666664%\n",
      "The precision of this classifier is 74.0%\n",
      "The recall of this classifier is 49.44320712694877%\n",
      "The F-measure of this classifier is 1.1989319092122832\n"
     ]
    }
   ],
   "source": [
    "q5_accuracy,q5_precision,q5_recall,q5_F_measure,q5_index = best_fit(q5_positive_values,q5_negative_values)\n",
    "print(\"value of k that performs the best is \", q5_index)\n",
    "print(\"The accuracy of this classifier is \" + str(100*q5_accuracy) + \"%\")\n",
    "print(\"The precision of this classifier is \" + str(100*q5_precision) + \"%\")\n",
    "print(\"The recall of this classifier is \" + str(100*q5_recall) + \"%\")\n",
    "print(\"The F-measure of this classifier is \" + str(2*q5_precision/(q5_precision + q5_recall)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
